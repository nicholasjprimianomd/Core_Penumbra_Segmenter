import numpy as np
import matplotlib.pyplot as plt
from pathlib import Path
import nibabel as nib
import os

def view_npz_prediction(npz_path, slice_idx=None, save_output=False, output_dir=None, 
                        interactive=True, multi_slice=False, num_slices=5):
    """
    Visualize prediction from a .npz file generated by nnUNet validation
    
    Args:
        npz_path (str): Path to the .npz prediction file
        slice_idx (int, optional): Specific slice to visualize. If None, will pick middle slice.
        save_output (bool): Whether to save the visualization
        output_dir (str): Directory to save visualization if save_output=True
        interactive (bool): Whether to enable interactive scrolling through slices
        multi_slice (bool): Whether to show multiple slices at once
        num_slices (int): Number of slices to show if multi_slice=True
    """
    print(f"Loading prediction from: {npz_path}")
    
    # Load the .npz file
    npz_data = np.load(npz_path, allow_pickle=True)
    
    # Print keys to understand what's in the file
    print(f"Keys in the .npz file: {list(npz_data.keys())}")
    
    # Determine if this is a prediction file - check for both 'softmax' and 'probabilities' keys
    prediction_key = None
    if 'softmax' in npz_data:
        prediction_key = 'softmax'
    elif 'probabilities' in npz_data:
        prediction_key = 'probabilities'
    
    if prediction_key is not None:
        pred_data = npz_data[prediction_key]
        print(f"Loaded {prediction_key} predictions. Shape: {pred_data.shape}")
        
        # For softmax/probabilities, the first dimension is likely the channel/class dimension
        n_classes = pred_data.shape[0]
        
        # Get the predicted class by taking argmax along the class dimension
        # For nnUNet, dimensions are typically (classes, z, x, y) or (classes, z, y, x)
        predicted_segmentation = np.argmax(pred_data, axis=0)
        print(f"Predicted segmentation shape: {predicted_segmentation.shape}")
        
        # Find corresponding .nii.gz file (ground truth)
        nii_path = npz_path.replace('.npz', '.nii.gz')
        
        has_ground_truth = False
        gt_data = None
        
        if os.path.exists(nii_path):
            print(f"Found corresponding ground truth at: {nii_path}")
            gt_img = nib.load(nii_path)
            gt_data = gt_img.get_fdata()
            print(f"Ground truth shape: {gt_data.shape}")
            has_ground_truth = True
            
            # NIfTI files typically have dimensions (x, y, z)
            # We need to transpose to match the prediction dimensions (z, x, y)
            # Check if dimensions need to be transposed based on shape comparison
            if gt_data.shape[2] == predicted_segmentation.shape[0]:
                # We need to transpose, NIfTI is (x,y,z) and prediction is (z,x,y) or (z,y,x)
                gt_data = np.transpose(gt_data, (2, 0, 1))
                print(f"Transposed ground truth shape: {gt_data.shape}")
        else:
            print(f"No corresponding ground truth found at: {nii_path}")
            
        # Determine total number of slices
        total_slices = predicted_segmentation.shape[0]
        print(f"Total slices: {total_slices}")

        # Determine slice to visualize if not provided
        if slice_idx is None:
            # Choose middle slice, ensuring it's valid for both arrays
            pred_max_z = predicted_segmentation.shape[0] - 1
            if has_ground_truth:
                gt_max_z = gt_data.shape[0] - 1
                slice_idx = min(pred_max_z, gt_max_z) // 2
            else:
                slice_idx = pred_max_z // 2
            print(f"Starting with slice {slice_idx}")
        else:
            # Validate the provided slice index
            if slice_idx >= predicted_segmentation.shape[0]:
                slice_idx = predicted_segmentation.shape[0] - 1
                print(f"Requested slice index too large for prediction data. Using slice {slice_idx} instead.")
            
            if has_ground_truth and slice_idx >= gt_data.shape[0]:
                old_slice = slice_idx
                slice_idx = min(slice_idx, gt_data.shape[0] - 1)
                print(f"Slice {old_slice} too large for ground truth. Using slice {slice_idx} instead.")

        if interactive:
            # Interactive visualization with scrolling capability
            class IndexTracker:
                def __init__(self, ax1, ax2, ax3, pred_data, gt_data, n_classes, has_gt):
                    self.ax1 = ax1
                    self.ax2 = ax2
                    self.ax3 = ax3
                    self.pred_data = pred_data
                    self.gt_data = gt_data
                    self.n_classes = n_classes
                    self.has_gt = has_gt
                    
                    self.current_idx = slice_idx
                    self.total_slices = total_slices
                    
                    # Initialize the plots
                    self.update()
                    
                def on_scroll(self, event):
                    if event.button == 'up':
                        self.current_idx = min(self.current_idx + 1, self.total_slices - 1)
                    elif event.button == 'down':
                        self.current_idx = max(self.current_idx - 1, 0)
                        
                    self.update()
                    
                def update(self):
                    # Clear axes
                    self.ax1.clear()
                    if self.has_gt:
                        self.ax2.clear()
                    self.ax3.clear()
                    
                    # Plot predicted segmentation
                    self.ax1.imshow(predicted_segmentation[self.current_idx], cmap='nipy_spectral')
                    self.ax1.set_title(f'Prediction (Slice {self.current_idx}/{self.total_slices-1})')
                    self.ax1.axis('off')
                    
                    # Plot ground truth if available
                    if self.has_gt:
                        self.ax2.imshow(self.gt_data[self.current_idx], cmap='nipy_spectral')
                        self.ax2.set_title(f'Ground Truth (Slice {self.current_idx})')
                        self.ax2.axis('off')
                    
                    # Plot overlay/difference if ground truth is available
                    if self.has_gt:
                        # Create a colored overlay to highlight differences
                        pred_shape = predicted_segmentation[self.current_idx].shape
                        overlay = np.zeros((*pred_shape, 3))
                        pred_slice = predicted_segmentation[self.current_idx]
                        gt_slice = self.gt_data[self.current_idx]
                        
                        # Create different colors for different types of errors
                        for class_idx in range(1, self.n_classes):  # Skip background class (0)
                            # True positives (green)
                            overlay[..., 1] += ((pred_slice == class_idx) & (gt_slice == class_idx)).astype(float) / self.n_classes
                            
                            # False positives (red)
                            overlay[..., 0] += ((pred_slice == class_idx) & (gt_slice != class_idx)).astype(float) / self.n_classes
                            
                            # False negatives (blue)
                            overlay[..., 2] += ((pred_slice != class_idx) & (gt_slice == class_idx)).astype(float) / self.n_classes
                        
                        self.ax3.imshow(overlay)
                        self.ax3.set_title('Difference: Red=FP, Green=TP, Blue=FN')
                    else:
                        # Without ground truth, show prediction confidence
                        pred_shape = predicted_segmentation[self.current_idx].shape
                        overlay = np.zeros((*pred_shape, 3))
                        
                        # Show probability of the predicted class
                        for i in range(pred_shape[0]):
                            for j in range(pred_shape[1]):
                                class_idx = predicted_segmentation[self.current_idx, i, j]
                                prob = pred_data[class_idx, self.current_idx, i, j]
                                
                                # Use color intensity based on prediction confidence
                                if class_idx == 0:  # Background
                                    continue  # Skip background
                                elif class_idx == 1:  # Class 1
                                    overlay[i, j, 0] = prob  # Red
                                elif class_idx == 2:  # Class 2
                                    overlay[i, j, 1] = prob  # Green
                                elif class_idx == 3:  # Class 3
                                    overlay[i, j, 2] = prob  # Blue
                        
                        self.ax3.imshow(overlay)
                        self.ax3.set_title('Prediction Confidence')
                    
                    self.ax3.axis('off')
                    plt.suptitle(f'Use mouse wheel to scroll through slices - Current: {self.current_idx}')
                    plt.draw()
                    
                    # Save current view if requested
                    if save_output and output_dir:
                        os.makedirs(output_dir, exist_ok=True)
                        output_path = os.path.join(output_dir, f"{Path(npz_path).stem}_slice{self.current_idx}.png")
                        plt.savefig(output_path, dpi=300, bbox_inches='tight')
                        print(f"Saved slice {self.current_idx} to: {output_path}")
            
            # Create figure and axes for interactive view
            if has_ground_truth:
                fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(18, 6))
            else:
                fig, (ax1, ax3) = plt.subplots(1, 2, figsize=(12, 6))
                ax2 = None
            
            # Initialize tracker
            tracker = IndexTracker(ax1, ax2, ax3, pred_data, gt_data, n_classes, has_ground_truth)
            
            # Connect scroll event
            fig.canvas.mpl_connect('scroll_event', tracker.on_scroll)
            
            plt.tight_layout()
            plt.show()
            
        elif multi_slice:
            # Show multiple slices in a grid
            # Calculate intervals for showing slices
            if num_slices > total_slices:
                num_slices = total_slices
                
            slice_interval = total_slices // num_slices
            slice_indices = [i * slice_interval for i in range(num_slices)]
            if slice_interval > 0 and slice_indices[-1] + slice_interval < total_slices:
                slice_indices.append(total_slices - 1)  # Add last slice
            
            # Determine grid dimensions
            grid_size = int(np.ceil(np.sqrt(len(slice_indices))))
            
            # Create a figure for visualization
            fig_pred = plt.figure(figsize=(15, 15))
            fig_pred.suptitle("Prediction Segmentation Slices", fontsize=16)
            
            # Plot each slice of prediction
            for i, slice_num in enumerate(slice_indices):
                ax = fig_pred.add_subplot(grid_size, grid_size, i+1)
                ax.imshow(predicted_segmentation[slice_num], cmap='nipy_spectral')
                ax.set_title(f'Slice {slice_num}')
                ax.axis('off')
            
            plt.tight_layout(rect=[0, 0, 1, 0.97])  # Adjust for suptitle
            
            # If we have ground truth, show it in a separate figure
            if has_ground_truth:
                fig_gt = plt.figure(figsize=(15, 15))
                fig_gt.suptitle("Ground Truth Slices", fontsize=16)
                
                for i, slice_num in enumerate(slice_indices):
                    ax = fig_gt.add_subplot(grid_size, grid_size, i+1)
                    ax.imshow(gt_data[slice_num], cmap='nipy_spectral')
                    ax.set_title(f'Slice {slice_num}')
                    ax.axis('off')
                
                plt.tight_layout(rect=[0, 0, 1, 0.97])
                
                # Also create a difference visualization
                fig_diff = plt.figure(figsize=(15, 15))
                fig_diff.suptitle("Difference (Red=FP, Green=TP, Blue=FN)", fontsize=16)
                
                for i, slice_num in enumerate(slice_indices):
                    ax = fig_diff.add_subplot(grid_size, grid_size, i+1)
                    
                    # Create overlay for this slice
                    pred_shape = predicted_segmentation[slice_num].shape
                    overlay = np.zeros((*pred_shape, 3))
                    pred_slice = predicted_segmentation[slice_num]
                    gt_slice = gt_data[slice_num]
                    
                    # Create different colors for different types of errors
                    for class_idx in range(1, n_classes):  # Skip background class (0)
                        # True positives (green)
                        overlay[..., 1] += ((pred_slice == class_idx) & (gt_slice == class_idx)).astype(float) / n_classes
                        
                        # False positives (red)
                        overlay[..., 0] += ((pred_slice == class_idx) & (gt_slice != class_idx)).astype(float) / n_classes
                        
                        # False negatives (blue)
                        overlay[..., 2] += ((pred_slice != class_idx) & (gt_slice == class_idx)).astype(float) / n_classes
                    
                    ax.imshow(overlay)
                    ax.set_title(f'Slice {slice_num}')
                    ax.axis('off')
                
                plt.tight_layout(rect=[0, 0, 1, 0.97])
            
            # Save figures if requested
            if save_output and output_dir:
                os.makedirs(output_dir, exist_ok=True)
                
                # Save prediction figure
                output_path = os.path.join(output_dir, f"{Path(npz_path).stem}_prediction_grid.png")
                fig_pred.savefig(output_path, dpi=300, bbox_inches='tight')
                print(f"Saved prediction grid to: {output_path}")
                
                # Save ground truth and difference if available
                if has_ground_truth:
                    output_path = os.path.join(output_dir, f"{Path(npz_path).stem}_groundtruth_grid.png")
                    fig_gt.savefig(output_path, dpi=300, bbox_inches='tight')
                    print(f"Saved ground truth grid to: {output_path}")
                    
                    output_path = os.path.join(output_dir, f"{Path(npz_path).stem}_difference_grid.png")
                    fig_diff.savefig(output_path, dpi=300, bbox_inches='tight')
                    print(f"Saved difference grid to: {output_path}")
            
            plt.show()
            
        else:
            # Default single slice view (non-interactive)
            if has_ground_truth:
                fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(18, 6))
            else:
                fig, (ax1, ax3) = plt.subplots(1, 2, figsize=(12, 6))
            
            # Plot predicted segmentation - now using first dimension as slice
            ax1.imshow(predicted_segmentation[slice_idx], cmap='nipy_spectral')
            ax1.set_title(f'Predicted Segmentation (Slice {slice_idx})')
            ax1.axis('off')
            
            # Plot ground truth if available
            if has_ground_truth:
                ax2.imshow(gt_data[slice_idx], cmap='nipy_spectral')
                ax2.set_title(f'Ground Truth (Slice {slice_idx})')
                ax2.axis('off')
            
            # Plot overlay/difference if ground truth is available
            if has_ground_truth:
                # Create a colored overlay to highlight differences
                # Now the shape should be (height, width, 3)
                pred_shape = predicted_segmentation[slice_idx].shape
                overlay = np.zeros((*pred_shape, 3))
                pred_slice = predicted_segmentation[slice_idx]
                gt_slice = gt_data[slice_idx]
                
                # Create different colors for different types of errors
                for class_idx in range(1, n_classes):  # Skip background class (0)
                    # True positives (green) - both prediction and ground truth agree
                    overlay[..., 1] += ((pred_slice == class_idx) & (gt_slice == class_idx)).astype(float) / n_classes
                    
                    # False positives (red) - prediction says yes, but ground truth says no
                    overlay[..., 0] += ((pred_slice == class_idx) & (gt_slice != class_idx)).astype(float) / n_classes
                    
                    # False negatives (blue) - prediction says no, but ground truth says yes
                    overlay[..., 2] += ((pred_slice != class_idx) & (gt_slice == class_idx)).astype(float) / n_classes
                
                ax3.imshow(overlay)
                ax3.set_title('Difference: Red=FP, Green=TP, Blue=FN')
            else:
                # Without ground truth, just show prediction probabilities
                # Display probability map for each class
                pred_shape = predicted_segmentation[slice_idx].shape
                overlay = np.zeros((*pred_shape, 3))
                
                # Show probability of the predicted class
                for i in range(pred_shape[0]):
                    for j in range(pred_shape[1]):
                        class_idx = predicted_segmentation[slice_idx, i, j]
                        prob = pred_data[class_idx, slice_idx, i, j]
                        
                        # Use color intensity based on prediction confidence
                        if class_idx == 0:  # Background
                            continue  # Skip background for clarity
                        elif class_idx == 1:  # Class 1 (e.g., "Core") 
                            overlay[i, j, 0] = prob  # Red
                        elif class_idx == 2:  # Class 2 (e.g., "Penumbra")
                            overlay[i, j, 1] = prob  # Green
                        elif class_idx == 3:  # Class 3 (if present)
                            overlay[i, j, 2] = prob  # Blue
                
                ax3.imshow(overlay)
                ax3.set_title('Prediction Confidence')
            
            ax3.axis('off')
            
            plt.tight_layout()
            
            if save_output and output_dir:
                os.makedirs(output_dir, exist_ok=True)
                output_path = os.path.join(output_dir, f"{Path(npz_path).stem}_slice{slice_idx}.png")
                plt.savefig(output_path, dpi=300, bbox_inches='tight')
                print(f"Saved visualization to: {output_path}")
            
            plt.show()
    
    else:
        print(f"Unrecognized .npz format. Expected 'softmax' or 'probabilities' key, found: {list(npz_data.keys())}")

if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="Visualize nnUNet prediction files (.npz)")
    parser.add_argument(
        "npz_path", 
        type=str, 
        help="Path to the .npz prediction file"
    )
    parser.add_argument(
        "--slice", 
        type=int, 
        default=None, 
        help="Slice index to visualize (default: middle slice)"
    )
    parser.add_argument(
        "--save", 
        action="store_true", 
        help="Save visualization to file"
    )
    parser.add_argument(
        "--output-dir", 
        type=str, 
        default="./visualization_output", 
        help="Directory to save visualizations"
    )
    parser.add_argument(
        "--interactive", 
        action="store_true", 
        help="Enable interactive slice scrolling"
    )
    parser.add_argument(
        "--multi-slice", 
        action="store_true", 
        help="Display multiple slices in a grid"
    )
    parser.add_argument(
        "--num-slices", 
        type=int, 
        default=9, 
        help="Number of slices to display when using --multi-slice (default: 9)"
    )
    
    args = parser.parse_args()
    
    view_npz_prediction(
        args.npz_path, 
        slice_idx=args.slice, 
        save_output=args.save, 
        output_dir=args.output_dir,
        interactive=args.interactive,
        multi_slice=args.multi_slice,
        num_slices=args.num_slices
    ) 